{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MIMIC-IV Clinical Notes Exploration\n",
    "\n",
    "This notebook explores the structure and content of MIMIC-IV clinical notes to inform model selection for text processing. We analyze:\n",
    "- **Discharge summaries** and **Radiology reports**\n",
    "- Text length distributions to determine if we need standard BERT (512 tokens) or Longformer/ModernBERT (8k+ tokens)\n",
    "- Linkage between text files and metadata (_detail) files\n",
    "\n",
    "**Context**: Preparing unstructured clinical text for an RL agent (P-CAFE)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1: Setup & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# Set plot style for better readability\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (14, 6)\n",
    "plt.rcParams['font.size'] = 10\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2: Define File Paths\n",
    "\n",
    "Update these paths to match your MIMIC-IV data location. The files should be in the `note` module of MIMIC-IV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define file paths - Update these to match your data location\n",
    "# Standard MIMIC-IV structure: physionet.org/files/mimiciv/3.1/note/\n",
    "\n",
    "# Adjust this base path to your MIMIC-IV data directory\n",
    "base_path = '/path/to/mimiciv/3.1/note/'\n",
    "\n",
    "# Clinical text files\n",
    "discharge_file = base_path + 'discharge.csv.gz'\n",
    "radiology_file = base_path + 'radiology.csv.gz'\n",
    "\n",
    "# Metadata files\n",
    "discharge_detail_file = base_path + 'discharge_detail.csv.gz'\n",
    "radiology_detail_file = base_path + 'radiology_detail.csv.gz'\n",
    "\n",
    "print(\"File paths defined.\")\n",
    "print(f\"Discharge: {discharge_file}\")\n",
    "print(f\"Discharge Detail: {discharge_detail_file}\")\n",
    "print(f\"Radiology: {radiology_file}\")\n",
    "print(f\"Radiology Detail: {radiology_detail_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3: Load Data (Optimized)\n",
    "\n",
    "Since note files contain large text fields, we load only the first 1,000 rows of each file to inspect structure without memory issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load discharge notes (first 1000 rows)\n",
    "print(\"Loading discharge notes (first 1000 rows)...\")\n",
    "discharge_df = pd.read_csv(discharge_file, nrows=1000, compression='gzip')\n",
    "print(f\"Discharge notes loaded: {len(discharge_df)} rows\")\n",
    "print(f\"Columns: {list(discharge_df.columns)}\")\n",
    "print(f\"Data types:\\n{discharge_df.dtypes}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load discharge detail (first 1000 rows)\n",
    "print(\"Loading discharge detail (first 1000 rows)...\")\n",
    "discharge_detail_df = pd.read_csv(discharge_detail_file, nrows=1000, compression='gzip')\n",
    "print(f\"Discharge detail loaded: {len(discharge_detail_df)} rows\")\n",
    "print(f\"Columns: {list(discharge_detail_df.columns)}\")\n",
    "print(f\"Data types:\\n{discharge_detail_df.dtypes}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load radiology notes (first 1000 rows)\n",
    "print(\"Loading radiology notes (first 1000 rows)...\")\n",
    "radiology_df = pd.read_csv(radiology_file, nrows=1000, compression='gzip')\n",
    "print(f\"Radiology notes loaded: {len(radiology_df)} rows\")\n",
    "print(f\"Columns: {list(radiology_df.columns)}\")\n",
    "print(f\"Data types:\\n{radiology_df.dtypes}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load radiology detail (first 1000 rows)\n",
    "print(\"Loading radiology detail (first 1000 rows)...\")\n",
    "radiology_detail_df = pd.read_csv(radiology_detail_file, nrows=1000, compression='gzip')\n",
    "print(f\"Radiology detail loaded: {len(radiology_detail_df)} rows\")\n",
    "print(f\"Columns: {list(radiology_detail_df.columns)}\")\n",
    "print(f\"Data types:\\n{radiology_detail_df.dtypes}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 4: Structure Analysis - Linkage Check\n",
    "\n",
    "Verify if `note_id`, `subject_id`, and `hadm_id` exist in both text files and detail files. Check for one-to-one relationships."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check common identifiers in discharge files\n",
    "print(\"=== DISCHARGE FILES LINKAGE ===\")\n",
    "print(f\"Discharge columns: {list(discharge_df.columns)}\")\n",
    "print(f\"Discharge Detail columns: {list(discharge_detail_df.columns)}\")\n",
    "print()\n",
    "\n",
    "# Check for common columns\n",
    "discharge_common_cols = set(discharge_df.columns).intersection(set(discharge_detail_df.columns))\n",
    "print(f\"Common columns between discharge and discharge_detail: {discharge_common_cols}\")\n",
    "print()\n",
    "\n",
    "# If note_id exists, check for one-to-one relationship\n",
    "if 'note_id' in discharge_df.columns and 'note_id' in discharge_detail_df.columns:\n",
    "    discharge_note_ids = set(discharge_df['note_id'])\n",
    "    discharge_detail_note_ids = set(discharge_detail_df['note_id'])\n",
    "    \n",
    "    # Check intersection\n",
    "    common_note_ids = discharge_note_ids.intersection(discharge_detail_note_ids)\n",
    "    print(f\"Total note_ids in discharge: {len(discharge_note_ids)}\")\n",
    "    print(f\"Total note_ids in discharge_detail: {len(discharge_detail_note_ids)}\")\n",
    "    print(f\"Common note_ids: {len(common_note_ids)}\")\n",
    "    \n",
    "    # Check for duplicates\n",
    "    discharge_duplicates = discharge_df['note_id'].duplicated().sum()\n",
    "    detail_duplicates = discharge_detail_df['note_id'].duplicated().sum()\n",
    "    print(f\"Duplicate note_ids in discharge: {discharge_duplicates}\")\n",
    "    print(f\"Duplicate note_ids in discharge_detail: {detail_duplicates}\")\n",
    "    \n",
    "    if discharge_duplicates == 0 and detail_duplicates == 0:\n",
    "        print(\"✓ One-to-one relationship confirmed for discharge files\")\n",
    "    else:\n",
    "        print(\"⚠ Warning: Duplicate note_ids found, relationship may not be one-to-one\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check common identifiers in radiology files\n",
    "print(\"=== RADIOLOGY FILES LINKAGE ===\")\n",
    "print(f\"Radiology columns: {list(radiology_df.columns)}\")\n",
    "print(f\"Radiology Detail columns: {list(radiology_detail_df.columns)}\")\n",
    "print()\n",
    "\n",
    "# Check for common columns\n",
    "radiology_common_cols = set(radiology_df.columns).intersection(set(radiology_detail_df.columns))\n",
    "print(f\"Common columns between radiology and radiology_detail: {radiology_common_cols}\")\n",
    "print()\n",
    "\n",
    "# If note_id exists, check for one-to-one relationship\n",
    "if 'note_id' in radiology_df.columns and 'note_id' in radiology_detail_df.columns:\n",
    "    radiology_note_ids = set(radiology_df['note_id'])\n",
    "    radiology_detail_note_ids = set(radiology_detail_df['note_id'])\n",
    "    \n",
    "    # Check intersection\n",
    "    common_note_ids = radiology_note_ids.intersection(radiology_detail_note_ids)\n",
    "    print(f\"Total note_ids in radiology: {len(radiology_note_ids)}\")\n",
    "    print(f\"Total note_ids in radiology_detail: {len(radiology_detail_note_ids)}\")\n",
    "    print(f\"Common note_ids: {len(common_note_ids)}\")\n",
    "    \n",
    "    # Check for duplicates\n",
    "    radiology_duplicates = radiology_df['note_id'].duplicated().sum()\n",
    "    detail_duplicates = radiology_detail_df['note_id'].duplicated().sum()\n",
    "    print(f\"Duplicate note_ids in radiology: {radiology_duplicates}\")\n",
    "    print(f\"Duplicate note_ids in radiology_detail: {detail_duplicates}\")\n",
    "    \n",
    "    if radiology_duplicates == 0 and detail_duplicates == 0:\n",
    "        print(\"✓ One-to-one relationship confirmed for radiology files\")\n",
    "    else:\n",
    "        print(\"⚠ Warning: Duplicate note_ids found, relationship may not be one-to-one\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 5: Metadata Inspection\n",
    "\n",
    "Display unique values of `note_type` or `description` from the detail files to understand what kinds of reports are available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect discharge detail metadata\n",
    "print(\"=== DISCHARGE DETAIL METADATA ===\")\n",
    "print(f\"Sample of discharge_detail:\")\n",
    "print(discharge_detail_df.head())\n",
    "print()\n",
    "\n",
    "# Check for note_type or description columns\n",
    "if 'note_type' in discharge_detail_df.columns:\n",
    "    print(f\"Unique note_type values in discharge_detail:\")\n",
    "    print(discharge_detail_df['note_type'].value_counts())\n",
    "    print()\n",
    "\n",
    "if 'description' in discharge_detail_df.columns:\n",
    "    print(f\"Unique description values in discharge_detail:\")\n",
    "    print(discharge_detail_df['description'].value_counts())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect radiology detail metadata\n",
    "print(\"=== RADIOLOGY DETAIL METADATA ===\")\n",
    "print(f\"Sample of radiology_detail:\")\n",
    "print(radiology_detail_df.head())\n",
    "print()\n",
    "\n",
    "# Check for note_type or description columns\n",
    "if 'note_type' in radiology_detail_df.columns:\n",
    "    print(f\"Unique note_type values in radiology_detail:\")\n",
    "    print(radiology_detail_df['note_type'].value_counts())\n",
    "    print()\n",
    "\n",
    "if 'description' in radiology_detail_df.columns:\n",
    "    print(f\"Unique description values in radiology_detail:\")\n",
    "    print(radiology_detail_df['description'].value_counts())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 6: Text Length Analysis (Crucial for Model Selection)\n",
    "\n",
    "Calculate word counts for each note to approximate token counts. This analysis will help determine whether we need:\n",
    "- **BERT**: Standard transformer (512 tokens max)\n",
    "- **Longformer/ModernBERT**: Extended context models (8k+ tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate word counts for discharge notes\n",
    "print(\"=== DISCHARGE NOTES TEXT LENGTH ANALYSIS ===\")\n",
    "\n",
    "if 'text' in discharge_df.columns:\n",
    "    # Calculate word count (simple split on whitespace)\n",
    "    discharge_df['word_count'] = discharge_df['text'].fillna('').apply(lambda x: len(str(x).split()))\n",
    "    \n",
    "    # Calculate statistics\n",
    "    mean_words = discharge_df['word_count'].mean()\n",
    "    median_words = discharge_df['word_count'].median()\n",
    "    max_words = discharge_df['word_count'].max()\n",
    "    percentile_95 = discharge_df['word_count'].quantile(0.95)\n",
    "    \n",
    "    print(f\"Word Count Statistics for Discharge Summaries:\")\n",
    "    print(f\"  Mean: {mean_words:.0f} words\")\n",
    "    print(f\"  Median: {median_words:.0f} words\")\n",
    "    print(f\"  Maximum: {max_words:.0f} words\")\n",
    "    print(f\"  95th Percentile: {percentile_95:.0f} words\")\n",
    "    print()\n",
    "    \n",
    "    # Calculate percentage exceeding BERT limit (512 tokens ≈ 512 words as rough approximation)\n",
    "    bert_limit = 512\n",
    "    exceeding_bert = (discharge_df['word_count'] > bert_limit).sum()\n",
    "    percent_exceeding = (exceeding_bert / len(discharge_df)) * 100\n",
    "    \n",
    "    print(f\"Notes exceeding BERT limit (512 words): {exceeding_bert}/{len(discharge_df)} ({percent_exceeding:.1f}%)\")\n",
    "    print()\n",
    "else:\n",
    "    print(\"Warning: 'text' column not found in discharge_df\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate word counts for radiology notes\n",
    "print(\"=== RADIOLOGY NOTES TEXT LENGTH ANALYSIS ===\")\n",
    "\n",
    "if 'text' in radiology_df.columns:\n",
    "    # Calculate word count (simple split on whitespace)\n",
    "    radiology_df['word_count'] = radiology_df['text'].fillna('').apply(lambda x: len(str(x).split()))\n",
    "    \n",
    "    # Calculate statistics\n",
    "    mean_words = radiology_df['word_count'].mean()\n",
    "    median_words = radiology_df['word_count'].median()\n",
    "    max_words = radiology_df['word_count'].max()\n",
    "    percentile_95 = radiology_df['word_count'].quantile(0.95)\n",
    "    \n",
    "    print(f\"Word Count Statistics for Radiology Reports:\")\n",
    "    print(f\"  Mean: {mean_words:.0f} words\")\n",
    "    print(f\"  Median: {median_words:.0f} words\")\n",
    "    print(f\"  Maximum: {max_words:.0f} words\")\n",
    "    print(f\"  95th Percentile: {percentile_95:.0f} words\")\n",
    "    print()\n",
    "    \n",
    "    # Calculate percentage exceeding BERT limit (512 tokens ≈ 512 words as rough approximation)\n",
    "    bert_limit = 512\n",
    "    exceeding_bert = (radiology_df['word_count'] > bert_limit).sum()\n",
    "    percent_exceeding = (exceeding_bert / len(radiology_df)) * 100\n",
    "    \n",
    "    print(f\"Notes exceeding BERT limit (512 words): {exceeding_bert}/{len(radiology_df)} ({percent_exceeding:.1f}%)\")\n",
    "    print()\n",
    "else:\n",
    "    print(\"Warning: 'text' column not found in radiology_df\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 7: Visualization - Word Count Histograms\n",
    "\n",
    "Plot histograms of word counts with a vertical line at 512 words (BERT limit) to visualize how many notes would be truncated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create figure with two subplots\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# BERT limit marker\n",
    "bert_limit = 512\n",
    "\n",
    "# Plot discharge notes word count histogram\n",
    "if 'word_count' in discharge_df.columns:\n",
    "    axes[0].hist(discharge_df['word_count'], bins=50, color='steelblue', alpha=0.7, edgecolor='black')\n",
    "    axes[0].axvline(x=bert_limit, color='red', linestyle='--', linewidth=2, label=f'BERT Limit ({bert_limit} words)')\n",
    "    axes[0].set_xlabel('Word Count', fontsize=12)\n",
    "    axes[0].set_ylabel('Frequency', fontsize=12)\n",
    "    axes[0].set_title('Discharge Summaries - Word Count Distribution', fontsize=14, fontweight='bold')\n",
    "    axes[0].legend(fontsize=10)\n",
    "    axes[0].grid(axis='y', alpha=0.3)\n",
    "else:\n",
    "    axes[0].text(0.5, 0.5, 'No word_count data for discharge notes', \n",
    "                 ha='center', va='center', transform=axes[0].transAxes)\n",
    "\n",
    "# Plot radiology notes word count histogram\n",
    "if 'word_count' in radiology_df.columns:\n",
    "    axes[1].hist(radiology_df['word_count'], bins=50, color='darkorange', alpha=0.7, edgecolor='black')\n",
    "    axes[1].axvline(x=bert_limit, color='red', linestyle='--', linewidth=2, label=f'BERT Limit ({bert_limit} words)')\n",
    "    axes[1].set_xlabel('Word Count', fontsize=12)\n",
    "    axes[1].set_ylabel('Frequency', fontsize=12)\n",
    "    axes[1].set_title('Radiology Reports - Word Count Distribution', fontsize=14, fontweight='bold')\n",
    "    axes[1].legend(fontsize=10)\n",
    "    axes[1].grid(axis='y', alpha=0.3)\n",
    "else:\n",
    "    axes[1].text(0.5, 0.5, 'No word_count data for radiology notes', \n",
    "                 ha='center', va='center', transform=axes[1].transAxes)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Histogram visualization complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 8: Sample Display\n",
    "\n",
    "Display one full example of a discharge summary and one radiology report to inspect formatting, headers, and de-identification tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display a sample discharge summary\n",
    "print(\"=\" * 80)\n",
    "print(\"SAMPLE DISCHARGE SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "if 'text' in discharge_df.columns and len(discharge_df) > 0:\n",
    "    # Get the first non-empty text\n",
    "    sample_discharge = discharge_df[discharge_df['text'].notna()].iloc[0]\n",
    "    \n",
    "    print(f\"Note ID: {sample_discharge.get('note_id', 'N/A')}\")\n",
    "    print(f\"Subject ID: {sample_discharge.get('subject_id', 'N/A')}\")\n",
    "    print(f\"Hospital Admission ID: {sample_discharge.get('hadm_id', 'N/A')}\")\n",
    "    print(f\"Word Count: {sample_discharge.get('word_count', 'N/A')}\")\n",
    "    print()\n",
    "    print(\"Text Content:\")\n",
    "    print(\"-\" * 80)\n",
    "    print(sample_discharge['text'])\n",
    "    print(\"-\" * 80)\n",
    "else:\n",
    "    print(\"No discharge text available to display.\")\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display a sample radiology report\n",
    "print(\"=\" * 80)\n",
    "print(\"SAMPLE RADIOLOGY REPORT\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "if 'text' in radiology_df.columns and len(radiology_df) > 0:\n",
    "    # Get the first non-empty text\n",
    "    sample_radiology = radiology_df[radiology_df['text'].notna()].iloc[0]\n",
    "    \n",
    "    print(f\"Note ID: {sample_radiology.get('note_id', 'N/A')}\")\n",
    "    print(f\"Subject ID: {sample_radiology.get('subject_id', 'N/A')}\")\n",
    "    print(f\"Hospital Admission ID: {sample_radiology.get('hadm_id', 'N/A')}\")\n",
    "    print(f\"Word Count: {sample_radiology.get('word_count', 'N/A')}\")\n",
    "    print()\n",
    "    print(\"Text Content:\")\n",
    "    print(\"-\" * 80)\n",
    "    print(sample_radiology['text'])\n",
    "    print(\"-\" * 80)\n",
    "else:\n",
    "    print(\"No radiology text available to display.\")\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary and Recommendations\n",
    "\n",
    "Based on the analysis above:\n",
    "\n",
    "1. **Model Selection**: Review the word count statistics and histogram visualizations to determine:\n",
    "   - If most notes are under 512 words → Standard BERT may be sufficient\n",
    "   - If many notes exceed 512 words → Consider Longformer or ModernBERT for longer context\n",
    "\n",
    "2. **Data Linkage**: The analysis shows how `note_id`, `subject_id`, and `hadm_id` link text files to metadata files.\n",
    "\n",
    "3. **Text Formatting**: Sample displays reveal the structure of clinical notes, including:\n",
    "   - De-identification tags (e.g., `[** ... **]`)\n",
    "   - Section headers\n",
    "   - Formatting conventions\n",
    "\n",
    "4. **Next Steps**:\n",
    "   - Update file paths in Section 2 to your actual MIMIC-IV data location\n",
    "   - Run the notebook to generate actual statistics\n",
    "   - Use the results to inform P-CAFE text processing strategy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
