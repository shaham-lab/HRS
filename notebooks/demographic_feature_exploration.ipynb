{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demographic Feature Exploration\n",
    "\n",
    "Extracts a compact demographic feature vector **[Age, Gender, Height (cm), Weight (kg)]** per admission (`hadm_id`) for the RL agent (P-CAFE).\n",
    "\n",
    "**Pipeline overview:**\n",
    "1. Age & Gender from `patients` / `admissions` core tables.\n",
    "2. Height, Weight, and BMI primarily from the outpatient `omr` table (closest record to `admittime`).\n",
    "3. Fallback to ICU `chartevents` when `omr` data is absent.\n",
    "4. Remaining NaNs are imputed with the dataset median.\n",
    "5. Final output saved as `demographic_features.parquet` with columns `subject_id`, `hadm_id`, `demographic_vec`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1: Setup & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust this base path to your MIMIC-IV data directory\n",
    "base_path = '~/data/physionet.org/files/mimiciv/3.1/'\n",
    "\n",
    "patients_file    = base_path + 'hosp/patients.csv.gz'\n",
    "admissions_file  = base_path + 'hosp/admissions.csv.gz'\n",
    "omr_file         = base_path + 'hosp/omr.csv.gz'\n",
    "chartevents_file = base_path + 'icu/chartevents.csv.gz'\n",
    "\n",
    "print(\"File paths defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2: Core Demographics (Age & Gender)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load core patient and admission data\n",
    "print(\"Loading patient and admission data for demographic features...\")\n",
    "\n",
    "patients_df = pd.read_csv(\n",
    "    patients_file,\n",
    "    usecols=['subject_id', 'gender', 'anchor_age', 'anchor_year']\n",
    ")\n",
    "print(f\"Patients loaded: {len(patients_df):,} rows\")\n",
    "\n",
    "admissions_df = pd.read_csv(\n",
    "    admissions_file,\n",
    "    usecols=['subject_id', 'hadm_id', 'admittime'],\n",
    "    parse_dates=['admittime']\n",
    ")\n",
    "print(f\"Admissions loaded: {len(admissions_df):,} rows\")\n",
    "\n",
    "# Merge patients and admissions on subject_id\n",
    "demo_df = admissions_df.merge(patients_df, on='subject_id', how='left')\n",
    "\n",
    "# Drop rows where hadm_id is NaN\n",
    "demo_df = demo_df.dropna(subset=['hadm_id'])\n",
    "\n",
    "# Calculate admission age\n",
    "demo_df['admission_age'] = (\n",
    "    demo_df['anchor_age'] + (demo_df['admittime'].dt.year - demo_df['anchor_year'])\n",
    ")\n",
    "\n",
    "# Encode gender as binary (M=0, F=1)\n",
    "demo_df['gender_encoded'] = demo_df['gender'].map({'M': 0, 'F': 1})\n",
    "\n",
    "print(f\"\\nMerged demographic data: {len(demo_df):,} rows\")\n",
    "print(f\"Age range: {demo_df['admission_age'].min():.1f} - {demo_df['admission_age'].max():.1f}\")\n",
    "print(f\"Gender distribution: {demo_df['gender'].value_counts().to_dict()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3: Process OMR Table (Primary Source for Vitals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unit conversion constants\n",
    "LBS_TO_KG    = 0.453592\n",
    "INCHES_TO_CM = 2.54\n",
    "\n",
    "# Process OMR table: pick the closest record to admittime for each (hadm_id, result_name) pair\n",
    "print(\"Loading and processing OMR table...\")\n",
    "omr_relevant = ['Weight (Lbs)', 'Height (Inches)', 'BMI (kg/m2)', 'BMI']\n",
    "\n",
    "omr_df = pd.read_csv(\n",
    "    omr_file,\n",
    "    usecols=['subject_id', 'chartdate', 'result_name', 'result_value'],\n",
    "    parse_dates=['chartdate']\n",
    ")\n",
    "omr_df = omr_df[omr_df['result_name'].isin(omr_relevant)].copy()\n",
    "omr_df['result_value'] = pd.to_numeric(omr_df['result_value'], errors='coerce')\n",
    "\n",
    "# Merge with admissions to get admittime\n",
    "adm_slim = demo_df[['subject_id', 'hadm_id', 'admittime']].copy()\n",
    "omr_merged = omr_df.merge(adm_slim, on='subject_id', how='inner')\n",
    "\n",
    "# Calculate absolute time difference between OMR chartdate and admission time\n",
    "omr_merged['time_diff'] = (omr_merged['admittime'] - omr_merged['chartdate']).abs()\n",
    "\n",
    "# For each hadm_id and result_name, keep only the closest measurement\n",
    "omr_merged = omr_merged.sort_values('time_diff')\n",
    "omr_closest = omr_merged.drop_duplicates(subset=['hadm_id', 'result_name'], keep='first')\n",
    "\n",
    "# Pivot: one row per hadm_id with a column for each result_name\n",
    "omr_pivot = omr_closest.pivot_table(\n",
    "    index='hadm_id',\n",
    "    columns='result_name',\n",
    "    values='result_value',\n",
    "    aggfunc='first'\n",
    ").reset_index()\n",
    "omr_pivot.columns.name = None\n",
    "\n",
    "rename_map = {\n",
    "    'Weight (Lbs)':  'omr_weight',\n",
    "    'Height (Inches)': 'omr_height',\n",
    "    'BMI (kg/m2)':   'omr_bmi',\n",
    "    'BMI':           'omr_bmi_alt',\n",
    "}\n",
    "omr_pivot = omr_pivot.rename(columns={k: v for k, v in rename_map.items() if k in omr_pivot.columns})\n",
    "\n",
    "# Consolidate BMI columns (prefer 'BMI (kg/m2)', fallback to 'BMI')\n",
    "if 'omr_bmi' not in omr_pivot.columns:\n",
    "    omr_pivot['omr_bmi'] = np.nan\n",
    "if 'omr_bmi_alt' in omr_pivot.columns:\n",
    "    omr_pivot['omr_bmi'] = omr_pivot['omr_bmi'].fillna(omr_pivot['omr_bmi_alt'])\n",
    "    omr_pivot = omr_pivot.drop(columns=['omr_bmi_alt'])\n",
    "if 'omr_weight' not in omr_pivot.columns:\n",
    "    omr_pivot['omr_weight'] = np.nan\n",
    "if 'omr_height' not in omr_pivot.columns:\n",
    "    omr_pivot['omr_height'] = np.nan\n",
    "\n",
    "# Convert units: Lbs -> Kg, Inches -> cm\n",
    "omr_pivot['omr_weight'] = omr_pivot['omr_weight'] * LBS_TO_KG\n",
    "omr_pivot['omr_height'] = omr_pivot['omr_height'] * INCHES_TO_CM\n",
    "\n",
    "print(f\"OMR pivot shape: {omr_pivot.shape}\")\n",
    "print(f\"Columns: {list(omr_pivot.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 4: Process Chartevents Table (Fallback Source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process chartevents in chunks for Weight and Height (fallback source)\n",
    "print(\"\\nReading chartevents in chunks for Weight and Height...\")\n",
    "\n",
    "# ItemIDs of interest\n",
    "CE_WEIGHT_KG   = 226512  # Weight (Kg)\n",
    "CE_WEIGHT_LBS  = 226531  # Weight (Lbs)\n",
    "CE_HEIGHT_CM   = 226730  # Height (cm)\n",
    "CE_HEIGHT_INCH = 226707  # Height (Inch)\n",
    "ce_target_ids  = [CE_WEIGHT_KG, CE_WEIGHT_LBS, CE_HEIGHT_CM, CE_HEIGHT_INCH]\n",
    "\n",
    "ce_chunks = []\n",
    "chunk_number = 0\n",
    "\n",
    "for chunk in pd.read_csv(\n",
    "    chartevents_file,\n",
    "    usecols=['hadm_id', 'itemid', 'valuenum'],\n",
    "    chunksize=1000000\n",
    "):\n",
    "    chunk_number += 1\n",
    "    filtered = chunk[chunk['itemid'].isin(ce_target_ids)].dropna(subset=['hadm_id', 'valuenum'])\n",
    "    if len(filtered) > 0:\n",
    "        ce_chunks.append(filtered)\n",
    "\n",
    "print(f\"Chunks processed: {chunk_number}\")\n",
    "\n",
    "ce_df = pd.concat(ce_chunks, ignore_index=True)\n",
    "ce_df['hadm_id'] = ce_df['hadm_id'].astype(int)\n",
    "\n",
    "# First non-null measurement per (hadm_id, itemid)\n",
    "ce_first = ce_df.groupby(['hadm_id', 'itemid'])['valuenum'].first().reset_index()\n",
    "ce_first.columns = ['hadm_id', 'itemid', 'valuenum']\n",
    "\n",
    "# Pivot to get one column per itemid\n",
    "ce_pivot = ce_first.pivot_table(\n",
    "    index='hadm_id', columns='itemid', values='valuenum', aggfunc='first'\n",
    ").reset_index()\n",
    "ce_pivot.columns.name = None\n",
    "ce_pivot.columns = ['hadm_id'] + [f'item_{c}' for c in ce_pivot.columns[1:]]\n",
    "\n",
    "# Build ce_weight_kg and ce_height_cm with unit conversion\n",
    "wkg_col   = f'item_{CE_WEIGHT_KG}'\n",
    "wlbs_col  = f'item_{CE_WEIGHT_LBS}'\n",
    "hcm_col   = f'item_{CE_HEIGHT_CM}'\n",
    "hinch_col = f'item_{CE_HEIGHT_INCH}'\n",
    "\n",
    "ce_pivot['ce_weight_kg'] = ce_pivot.get(wkg_col, pd.Series(dtype=float))\n",
    "if wlbs_col in ce_pivot.columns:\n",
    "    ce_pivot['ce_weight_kg'] = ce_pivot['ce_weight_kg'].fillna(ce_pivot[wlbs_col] * LBS_TO_KG)\n",
    "\n",
    "ce_pivot['ce_height_cm'] = ce_pivot.get(hcm_col, pd.Series(dtype=float))\n",
    "if hinch_col in ce_pivot.columns:\n",
    "    ce_pivot['ce_height_cm'] = ce_pivot['ce_height_cm'].fillna(ce_pivot[hinch_col] * INCHES_TO_CM)\n",
    "\n",
    "ce_out = ce_pivot[['hadm_id', 'ce_weight_kg', 'ce_height_cm']].copy()\n",
    "print(f\"Chartevents fallback shape: {ce_out.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 5: Consolidate & Fallback Logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge Core Demographics, OMR data, and Chartevents data on hadm_id\n",
    "print(\"\\nMerging core demographics, OMR and chartevents data...\")\n",
    "\n",
    "full_df = demo_df[['subject_id', 'hadm_id', 'admittime', 'admission_age', 'gender_encoded']].copy()\n",
    "full_df = full_df.merge(omr_pivot, on='hadm_id', how='left')\n",
    "full_df = full_df.merge(ce_out, on='hadm_id', how='left')\n",
    "\n",
    "# Final weight/height: OMR first, fallback to chartevents\n",
    "full_df['final_weight_kg'] = full_df['omr_weight'].fillna(full_df['ce_weight_kg'])\n",
    "full_df['final_height_cm'] = full_df['omr_height'].fillna(full_df['ce_height_cm'])\n",
    "full_df['final_bmi']       = full_df['omr_bmi'].copy()\n",
    "\n",
    "# Calculate BMI dynamically if missing but weight and height are available\n",
    "missing_bmi_mask = (\n",
    "    full_df['final_bmi'].isna() &\n",
    "    full_df['final_weight_kg'].notna() &\n",
    "    full_df['final_height_cm'].notna() &\n",
    "    (full_df['final_height_cm'] > 0)\n",
    ")\n",
    "full_df.loc[missing_bmi_mask, 'final_bmi'] = (\n",
    "    full_df.loc[missing_bmi_mask, 'final_weight_kg'] /\n",
    "    (full_df.loc[missing_bmi_mask, 'final_height_cm'] / 100) ** 2\n",
    ")\n",
    "\n",
    "# Impute remaining NaNs with the dataset median\n",
    "weight_median = full_df['final_weight_kg'].median()\n",
    "height_median = full_df['final_height_cm'].median()\n",
    "age_median    = full_df['admission_age'].median()\n",
    "\n",
    "full_df['final_weight_kg'] = full_df['final_weight_kg'].fillna(weight_median)\n",
    "full_df['final_height_cm'] = full_df['final_height_cm'].fillna(height_median)\n",
    "full_df['admission_age']   = full_df['admission_age'].fillna(age_median)\n",
    "full_df['gender_encoded']  = full_df['gender_encoded'].fillna(0)  # Default to M=0 if missing\n",
    "\n",
    "print(f\"Consolidated dataframe shape: {full_df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 6: Vector Creation & Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print missing data statistics\n",
    "total_adm = len(full_df)\n",
    "\n",
    "omr_weight_pct   = full_df['omr_weight'].notna().sum()      / total_adm * 100\n",
    "omr_height_pct   = full_df['omr_height'].notna().sum()      / total_adm * 100\n",
    "omr_bmi_pct      = full_df['omr_bmi'].notna().sum()         / total_adm * 100\n",
    "final_weight_pct = full_df['final_weight_kg'].notna().sum() / total_adm * 100\n",
    "final_height_pct = full_df['final_height_cm'].notna().sum() / total_adm * 100\n",
    "final_bmi_pct    = full_df['final_bmi'].notna().sum()        / total_adm * 100\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"WEIGHT / HEIGHT / BMI AVAILABILITY\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"{'Metric':<20} {'OMR only':>12} {'After fallback':>16}\")\n",
    "print(\"-\" * 52)\n",
    "print(f\"{'Weight':<20} {omr_weight_pct:>11.1f}% {final_weight_pct:>15.1f}%\")\n",
    "print(f\"{'Height':<20} {omr_height_pct:>11.1f}% {final_height_pct:>15.1f}%\")\n",
    "print(f\"{'BMI':<20} {omr_bmi_pct:>11.1f}% {final_bmi_pct:>15.1f}%\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create demographic_vec column: [age, gender, final_height_cm, final_weight_kg]\n",
    "print(\"\\nCreating demographic feature vectors...\")\n",
    "\n",
    "stack = np.column_stack([\n",
    "    full_df['admission_age'].values,\n",
    "    full_df['gender_encoded'].values,\n",
    "    full_df['final_height_cm'].values,\n",
    "    full_df['final_weight_kg'].values,\n",
    "])\n",
    "full_df['demographic_vec'] = list(stack)\n",
    "\n",
    "# Save final dataframe with ONLY subject_id, hadm_id, and demographic_vec\n",
    "output_df = full_df[['subject_id', 'hadm_id', 'demographic_vec']].copy()\n",
    "\n",
    "output_file = '../data/output/demographic_features.parquet'\n",
    "output_df.to_parquet(output_file, index=False)\n",
    "\n",
    "print(f\"Demographic features saved to: {output_file}\")\n",
    "print(f\"Output shape: {output_df.shape}\")\n",
    "print(f\"\\nFirst 5 rows:\")\n",
    "print(output_df.head())\n",
    "\n",
    "# Verify vector format\n",
    "sample_vec = output_df['demographic_vec'].iloc[0]\n",
    "print(f\"\\nSample demographic_vec: {sample_vec}\")\n",
    "print(f\"Vector format: [Age={sample_vec[0]:.1f}, Gender={sample_vec[1]}, Height={sample_vec[2]:.1f}cm, Weight={sample_vec[3]:.1f}kg]\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}